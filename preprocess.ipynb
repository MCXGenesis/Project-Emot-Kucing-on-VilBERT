{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bdcad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "064705a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m folder_path = \u001b[33m\"\u001b[39m\u001b[33mAll Data Source\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Read a single CSV file from the folder\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m sample_file = \u001b[43mos\u001b[49m.path.join(folder_path, \u001b[33m'\u001b[39m\u001b[33mcombined_data.csv\u001b[39m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# Replace 'sample.csv' with your actual filename\u001b[39;00m\n\u001b[32m      5\u001b[39m df_com = pd.read_csv(sample_file)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSuccessfully loaded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos.path.basename(sample_file)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "folder_path = \"All Data Source\"\n",
    "\n",
    "# Read a single CSV file from the folder\n",
    "sample_file = os.path.join(folder_path, 'combined_data.csv')  # Replace 'sample.csv' with your actual filename\n",
    "df_com = pd.read_csv(sample_file)\n",
    "print(f\"Successfully loaded: {os.path.basename(sample_file)}\")\n",
    "print(df_com.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1b9c547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Konten yang beredar merupakan hasil rekayasa A...\n",
       "1       Video yang beredar adalah hasil rekayasa AI.\\n...\n",
       "2       Faktanya, ledakan hanya mungkin terjadi bila t...\n",
       "3       Faktanya Kemenaker menyalurkan BSU pada Juni-J...\n",
       "4       Faktanya, pengecekan BSU melalui Pospay hanya ...\n",
       "                              ...                        \n",
       "9995    Hasil Periksa Fakta Khairunnisa Andini (Univer...\n",
       "9996    Hasil Periksa Fakta Ani Nur MR (Universitas Ai...\n",
       "9997    Hasil Periksa Fakta Gabriela Nauli Sinaga (Uni...\n",
       "9998    Hasil periksa fakta Aisyah Adilah (Anggota Kom...\n",
       "9999    Direktorat Jenderal Imigrasi Kemenkumham menya...\n",
       "Name: Content, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_tbh['Content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bfb079",
   "metadata": {},
   "source": [
    "Berdasarkan struktur narasi TurnBackHoax, kita perlu mengambil bagian narasinya saja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45d3cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ambil_narasi_aja(full_text):\n",
    "    narasi=''\n",
    "    narasi_start_splitter = ['NARASI:', 'Narasi(Diterjemahkan ke Bahasa Indonesia)', '[NARASI]:', 'Narasi :', '[NARASI]', 'Narasi:', 'NARASI :']\n",
    "    for s in narasi_start_splitter:\n",
    "        if s in full_text:\n",
    "            narasi = full_text.split(s)[1]\n",
    "            break\n",
    "    narasi_ended = ''\n",
    "    narasi_end_splitter = ['PENJELASAN:', '[PENJELASAN]:', 'Penjelasan :', '[PENJELASAN]', 'PENJELASAN', 'PENJELASAN :']\n",
    "    for s in narasi_end_splitter:\n",
    "        if s in full_text:\n",
    "            narasi_ended = narasi.split(s)[0]\n",
    "            break\n",
    "\n",
    "    if len(narasi_ended) > 0:\n",
    "        narasi = narasi_ended\n",
    "\n",
    "    narasi_cont = ''\n",
    "    narasi_cont_splitter = ['(Lanjutan Narasi)']\n",
    "    for s in narasi_cont_splitter:\n",
    "        if s in full_text:\n",
    "            narasi_cont = full_text.split(s)[1]\n",
    "\n",
    "    narasi_full = narasi + '' + narasi_cont\n",
    "\n",
    "    return narasi_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e769805",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_tbh['Clean Narasi'] = df_raw_tbh['Content'].map(lambda x: ambil_narasi_aja(x))\n",
    "df_raw_tbh['Clean Narasi'] = df_raw_tbh['Clean Narasi'].str.lower()\n",
    "df_raw_tbh['Title'] = df_raw_tbh['Title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00be6c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                        \n",
       "1                                                        \n",
       "2                                                        \n",
       "3                                                        \n",
       "4                                                        \n",
       "                              ...                        \n",
       "9995          \\n“bill gates 1963 #billgates”\\n= = = = =\\n\n",
       "9996    \\n*poster jk-ahy\\n“deklarasi dukungan !\\ndemok...\n",
       "9997    \\n“medical shocker: scientists at sloan ketter...\n",
       "9998    \\npihak medis menjawab banyak faktor .. salah ...\n",
       "9999                                                     \n",
       "Name: Clean Narasi, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_tbh['Clean Narasi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e614ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(textDisplay):\n",
    "    if textDisplay is not None and isinstance(textDisplay, str):\n",
    "        url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "        return url.sub(r'', textDisplay)\n",
    "    else:\n",
    "        return textDisplay\n",
    "    \n",
    "def remove_html(textDisplay):\n",
    "    if textDisplay is not None and isinstance(textDisplay, str):\n",
    "        html = re.compile(r'<.*?>')\n",
    "        return html.sub(r'', textDisplay)\n",
    "    else:\n",
    "        return textDisplay\n",
    "    \n",
    "# def remove_emoji(textDisplay):\n",
    "#     if textDisplay is not None and isinstance(textDisplay, str):\n",
    "\n",
    "def remove_symbol(textDisplay):\n",
    "    if textDisplay is not None and isinstance(textDisplay, str):\n",
    "        textDisplay = re.sub(r'[^a-zA-Z0-9\\s]','',textDisplay)\n",
    "    return textDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "600c2dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_tbh['Title'] = df_raw_tbh['Title'].apply(lambda x: remove_html(x))\n",
    "df_raw_tbh['Title'] = df_raw_tbh['Title'].apply(lambda x: remove_symbol(x))\n",
    "df_raw_tbh['Title'] = df_raw_tbh['Title'].apply(lambda x: remove_url(x))\n",
    "\n",
    "df_raw_tbh['Clean Narasi'] = df_raw_tbh['Clean Narasi'].apply(lambda x: remove_html(x))\n",
    "df_raw_tbh['Clean Narasi'] = df_raw_tbh['Clean Narasi'].apply(lambda x: remove_symbol(x))\n",
    "df_raw_tbh['Clean Narasi'] = df_raw_tbh['Clean Narasi'].apply(lambda x: remove_url(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19be10dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\naufalmaula\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\naufalmaula\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "list_stopwords = stopwords.words(\"indonesian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74f84878",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_tbh['Clean Narasi'] = df_raw_tbh['Clean Narasi'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in list_stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84fe0c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title             0\n",
       "Content           0\n",
       "Image Filename    2\n",
       "Clean Narasi      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_tbh.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e054ce5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df_raw_tbh.to_csv('dataframe_turnbackhoax.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
