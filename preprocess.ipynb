{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bdcad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
<<<<<<< HEAD
    "import numpy as np\n",
    "import re\n"
=======
    "import numpy as np"
>>>>>>> 308aaef3f0526250053258431261ead605bb8068
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 6,
>>>>>>> 308aaef3f0526250053258431261ead605bb8068
   "id": "064705a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_tbh = pd.read_csv('turnbackhoax_data.csv')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 7,
>>>>>>> 308aaef3f0526250053258431261ead605bb8068
   "id": "f1b9c547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Konten yang beredar merupakan hasil rekayasa A...\n",
       "1       Video yang beredar adalah hasil rekayasa AI.\\n...\n",
       "2       Faktanya, ledakan hanya mungkin terjadi bila t...\n",
       "3       Faktanya Kemenaker menyalurkan BSU pada Juni-J...\n",
       "4       Faktanya, pengecekan BSU melalui Pospay hanya ...\n",
       "                              ...                        \n",
       "9995    Hasil Periksa Fakta Khairunnisa Andini (Univer...\n",
       "9996    Hasil Periksa Fakta Ani Nur MR (Universitas Ai...\n",
       "9997    Hasil Periksa Fakta Gabriela Nauli Sinaga (Uni...\n",
       "9998    Hasil periksa fakta Aisyah Adilah (Anggota Kom...\n",
       "9999    Direktorat Jenderal Imigrasi Kemenkumham menya...\n",
       "Name: Content, Length: 10000, dtype: object"
      ]
     },
<<<<<<< HEAD
     "execution_count": 3,
=======
     "execution_count": 7,
>>>>>>> 308aaef3f0526250053258431261ead605bb8068
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_tbh['Content']"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "id": "18bfb079",
   "metadata": {},
   "source": [
    "Berdasarkan struktur narasi TurnBackHoax, kita perlu mengambil bagian narasinya saja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
=======
   "cell_type": "code",
   "execution_count": null,
>>>>>>> 308aaef3f0526250053258431261ead605bb8068
   "id": "a45d3cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ambil_narasi_aja(full_text):\n",
    "    narasi=''\n",
    "    narasi_start_splitter = ['NARASI:', 'Narasi(Diterjemahkan ke Bahasa Indonesia)', '[NARASI]:', 'Narasi :', '[NARASI]', 'Narasi:', 'NARASI :']\n",
    "    for s in narasi_start_splitter:\n",
    "        if s in full_text:\n",
    "            narasi = full_text.split(s)[1]\n",
    "            break\n",
    "    narasi_ended = ''\n",
    "    narasi_end_splitter = ['PENJELASAN:', '[PENJELASAN]:', 'Penjelasan :', '[PENJELASAN]', 'PENJELASAN', 'PENJELASAN :']\n",
    "    for s in narasi_end_splitter:\n",
    "        if s in full_text:\n",
<<<<<<< HEAD
    "            narasi_ended = narasi.split(s)[0]\n",
    "            break\n",
    "\n",
    "    if len(narasi_ended) > 0:\n",
    "        narasi = narasi_ended\n",
    "\n",
    "    narasi_cont = ''\n",
    "    narasi_cont_splitter = ['(Lanjutan Narasi)']\n",
    "    for s in narasi_cont_splitter:\n",
    "        if s in full_text:\n",
    "            narasi_cont = full_text.split(s)[1]\n",
    "\n",
    "    narasi_full = narasi + '' + narasi_cont\n",
    "\n",
    "    return narasi_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e769805",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_tbh['Clean Narasi'] = df_raw_tbh['Content'].map(lambda x: ambil_narasi_aja(x))\n",
    "df_raw_tbh['Clean Narasi'] = df_raw_tbh['Clean Narasi'].str.lower()\n",
    "df_raw_tbh['Title'] = df_raw_tbh['Title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00be6c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                        \n",
       "1                                                        \n",
       "2                                                        \n",
       "3                                                        \n",
       "4                                                        \n",
       "                              ...                        \n",
       "9995          \\n“bill gates 1963 #billgates”\\n= = = = =\\n\n",
       "9996    \\n*poster jk-ahy\\n“deklarasi dukungan !\\ndemok...\n",
       "9997    \\n“medical shocker: scientists at sloan ketter...\n",
       "9998    \\npihak medis menjawab banyak faktor .. salah ...\n",
       "9999                                                     \n",
       "Name: Clean Narasi, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_tbh['Clean Narasi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e614ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(textDisplay):\n",
    "    if textDisplay is not None and isinstance(textDisplay, str):\n",
    "        url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "        return url.sub(r'', textDisplay)\n",
    "    else:\n",
    "        return textDisplay\n",
    "    \n",
    "def remove_html(textDisplay):\n",
    "    if textDisplay is not None and isinstance(textDisplay, str):\n",
    "        html = re.compile(r'<.*?>')\n",
    "        return html.sub(r'', textDisplay)\n",
    "    else:\n",
    "        return textDisplay\n",
    "    \n",
    "# def remove_emoji(textDisplay):\n",
    "#     if textDisplay is not None and isinstance(textDisplay, str):\n",
    "\n",
    "def remove_symbol(textDisplay):\n",
    "    if textDisplay is not None and isinstance(textDisplay, str):\n",
    "        textDisplay = re.sub(r'[^a-zA-Z0-9\\s]','',textDisplay)\n",
    "    return textDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "600c2dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_tbh['Title'] = df_raw_tbh['Title'].apply(lambda x: remove_html(x))\n",
    "df_raw_tbh['Title'] = df_raw_tbh['Title'].apply(lambda x: remove_symbol(x))\n",
    "df_raw_tbh['Title'] = df_raw_tbh['Title'].apply(lambda x: remove_url(x))\n",
    "\n",
    "df_raw_tbh['Clean Narasi'] = df_raw_tbh['Clean Narasi'].apply(lambda x: remove_html(x))\n",
    "df_raw_tbh['Clean Narasi'] = df_raw_tbh['Clean Narasi'].apply(lambda x: remove_symbol(x))\n",
    "df_raw_tbh['Clean Narasi'] = df_raw_tbh['Clean Narasi'].apply(lambda x: remove_url(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19be10dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\naufalmaula\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\naufalmaula\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "list_stopwords = stopwords.words(\"indonesian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74f84878",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_tbh['Clean Narasi'] = df_raw_tbh['Clean Narasi'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in list_stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84fe0c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title             0\n",
       "Content           0\n",
       "Image Filename    2\n",
       "Clean Narasi      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_tbh.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e054ce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_tbh.to_csv('dataframe_turnbackhoax.csv', index=False)"
=======
    "            narasi_ended = narasi.split(s)[1]\n",
    "            break\n",
    "\n",
    "    "
>>>>>>> 308aaef3f0526250053258431261ead605bb8068
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
